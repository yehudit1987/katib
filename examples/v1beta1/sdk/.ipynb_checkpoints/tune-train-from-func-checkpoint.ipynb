{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf9ab16d-fbf6-4385-a7f8-133e4562e1e7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Tune and Train with Kubeflow Katib and Training Operator\n",
    " \n",
    "In this Notebook we are going to do the following:\n",
    "\n",
    "- Train Tensorflow model using Kubeflow Notebook.\n",
    "- Improve the model HyperParameters with [Kubeflow Katib](https://www.kubeflow.org/docs/components/katib/overview/).\n",
    "- Use [Multi Worker Mirrored Strategy](https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/MultiWorkerMirroredStrategy) to distributively train the model with [Kubeflow TFJob](https://www.kubeflow.org/docs/components/training/tftraining/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d91e3d-904a-4a3c-b4e7-573324ba625e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Install Kubeflow Python SDKs\n",
    "\n",
    "You need to install Tensorflow package and Kubeflow SDKs to run this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd93498d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install kubeflow-katib\n",
    "!pip install tensorflow\n",
    "!pip install kubeflow-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4266314",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Experiment namespace\n",
    "namespace = \"default\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803efa63",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create Train Script for CNN Model\n",
    "\n",
    "This is simple **Convolutional Neural Network (CNN)** model for recognizing hand-written digits using [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9683f6ed",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_mnist_model(parameters):\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    import logging\n",
    "\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s %(levelname)-8s %(message)s\",\n",
    "        datefmt=\"%Y-%m-%dT%H:%M:%SZ\",\n",
    "        level=logging.INFO,\n",
    "    )\n",
    "    logging.info(\"--------------------------------------------------------------------------------------\")\n",
    "    logging.info(f\"Input Parameters: {parameters}\")\n",
    "    logging.info(\"--------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "    # Get HyperParameters from the input params dict.\n",
    "    lr = float(parameters[\"lr\"])\n",
    "    num_epoch = int(parameters[\"num_epoch\"])\n",
    "\n",
    "    # Set dist parameters and strategy.\n",
    "    is_dist = parameters[\"is_dist\"]\n",
    "    num_workers = parameters[\"num_workers\"]\n",
    "    batch_size_per_worker = 64\n",
    "    batch_size_global = batch_size_per_worker * num_workers\n",
    "    strategy = tf.distribute.MultiWorkerMirroredStrategy(\n",
    "        communication_options=tf.distribute.experimental.CommunicationOptions(\n",
    "            implementation=tf.distribute.experimental.CollectiveCommunication.RING\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Callback class for logging training.\n",
    "    # Katib parses metrics in this format: <metric-name>=<metric-value>.\n",
    "    class CustomCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            logging.info(\n",
    "                \"Epoch {}/{}. accuracy={:.4f} - loss={:.4f}\".format(\n",
    "                    epoch+1, num_epoch, logs[\"accuracy\"], logs[\"loss\"]\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Prepare MNIST Dataset.\n",
    "    def mnist_dataset(batch_size):\n",
    "        (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "        x_train = x_train / np.float32(255)\n",
    "        y_train = y_train.astype(np.int64)\n",
    "        train_dataset = (\n",
    "            tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "            .shuffle(60000)\n",
    "            .repeat()\n",
    "            .batch(batch_size)\n",
    "        )\n",
    "        return train_dataset\n",
    "\n",
    "    # Build and compile CNN Model.\n",
    "    def build_and_compile_cnn_model():\n",
    "        model = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "                tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "                tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "                tf.keras.layers.Dense(10),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=lr),\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "    # Download Dataset.\n",
    "    dataset = mnist_dataset(batch_size_global)\n",
    "\n",
    "    # For dist strategy we should build model under scope().\n",
    "    if is_dist:\n",
    "        logging.info(\"Running Distributed Training\")\n",
    "        logging.info(\"--------------------------------------------------------------------------------------\\n\\n\")\n",
    "        with strategy.scope():\n",
    "            model = build_and_compile_cnn_model()\n",
    "    else:\n",
    "        logging.info(\"Running Single Worker Training\")\n",
    "        logging.info(\"--------------------------------------------------------------------------------------\\n\\n\")\n",
    "        model = build_and_compile_cnn_model()\n",
    "    \n",
    "    # Start Training.\n",
    "    model.fit(\n",
    "        dataset,\n",
    "        epochs=num_epoch,\n",
    "        steps_per_epoch=70,\n",
    "        callbacks=[CustomCallback()],\n",
    "        verbose=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a633fe",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run Training Locally in the Notebook\n",
    "\n",
    "We are going to download MNIST Dataset and start local training.\n",
    "\n",
    "Also, set `Epochs = 2` to reduce training time and avoid CPU overload. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b1542",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set Parameters for Local Training.\n",
    "parameters = {\n",
    "    \"lr\": \"0.1\",\n",
    "    \"num_epoch\": \"2\",\n",
    "    \"is_dist\": False,\n",
    "    \"num_workers\": 1\n",
    "}\n",
    "\n",
    "# Train Model locally in the Notebook.\n",
    "train_mnist_model(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799e29c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Start Model Tuning with Katib\n",
    "\n",
    "If you want to improve your model, you can run HyperParameter tuning with Katib.\n",
    "\n",
    "The following example uses **Covariance Matrix Adaptation Evolution Strategy (CMA-ES)** algorithm to tune HyperParameters.\n",
    "\n",
    "We are going to tune `learning rate` and `number of epochs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd20618b",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kubeflow.katib as katib\n",
    "\n",
    "# Set parameters with their distribution for HyperParameter Tuning with Katib.\n",
    "parameters = {\n",
    "    \"lr\": katib.search.double(min=0.1, max=0.2),\n",
    "    \"num_epoch\": katib.search.int(min=10, max=15),\n",
    "    \"is_dist\": False,\n",
    "    \"num_workers\": 1\n",
    "}\n",
    "\n",
    "# Start the Katib Experiment.\n",
    "exp_name = \"tune-mnist\"\n",
    "katib_client = katib.KatibClient(namespace=namespace)\n",
    "\n",
    "katib_client.tune(\n",
    "    name=exp_name,\n",
    "    objective=train_mnist_model, # Objective function.\n",
    "    parameters=parameters, # HyperParameters to tune.\n",
    "    algorithm_name=\"cmaes\", # Alorithm to use.\n",
    "    objective_metric_name=\"accuracy\", # Katib is going to optimize \"accuracy\".\n",
    "    additional_metric_names=[\"loss\"], # Katib is going to collect these metrics in addition to the objective metric.\n",
    "    max_trial_count=12, # Trial Threshold.\n",
    "    parallel_trial_count=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2bfbd8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Access to Katib UI\n",
    "\n",
    "You can check created Experiment in the Katib UI.\n",
    "\n",
    "![Screenshot 2022-09-12 at 20.06.23.png](attachment:cdaf463d-28b3-4a98-bb4c-9613ca1bfa50.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9064db44",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get the Best HyperParameters from the Katib Experiment\n",
    "\n",
    "You can get the best HyperParameters from the most optimal Katib Trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b09e72",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "katib_client.wait_for_experiment_condition(exp_name, namespace=namespace, timeout=900)\n",
    "status = katib_client.is_experiment_succeeded(exp_name, namespace=namespace)\n",
    "print(f\"Katib Experiment is Succeeded: {status}\\n\")\n",
    "\n",
    "best_hps = katib_client.get_optimal_hyperparameters(exp_name, namespace=namespace)\n",
    "\n",
    "if best_hps != None:\n",
    "    print(\"Current Optimal Trial\\n\")\n",
    "    print(best_hps)\n",
    "    \n",
    "    for hp in best_hps.parameter_assignments:\n",
    "        if hp.name == \"lr\":\n",
    "            best_lr = hp.value\n",
    "        else:\n",
    "            best_num_epoch = hp.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfb1788",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Start Distributive Training with TFJob\n",
    "\n",
    "Use the best HyperParameters (`learning rate` and `number of epochs`) from the Katib Experiment and run the TFJob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff03f20f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from kubeflow.training import TrainingClient\n",
    "\n",
    "# Set Parameters for Distributed Training with TFJob.\n",
    "parameters = {\n",
    "    \"lr\": best_lr,\n",
    "    \"num_epoch\": best_num_epoch,\n",
    "    \"is_dist\": True,\n",
    "    \"num_workers\": 5\n",
    "}\n",
    "\n",
    "# Start TFJob Training.\n",
    "tfjob_name = \"train-mnist\"\n",
    "tfjob_client = TrainingClient(namespace=namespace)\n",
    "\n",
    "#create_tfjob_from_func\n",
    "tfjob_client.create_job(\n",
    "    name=tfjob_name,\n",
    "    namespace=namespace,\n",
    "    job_kind=\"TFJob\",\n",
    "    train_func=train_mnist_model,\n",
    "    parameters=parameters, # Input parameters for the train function.\n",
    "    num_workers=5, # How many TFJob Workers will be run.\n",
    "    base_image=\"tensorflow/tensorflow:2.10.0\",  # Use TensorFlow image\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d465e8-0310-4c72-ad36-209259ad5c34",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get TFJob Status and Training Logs\n",
    "\n",
    "You can check the TFJob status and logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53859cf4-7a35-4fc4-b5ee-9ba774635df0",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-09-12T19:10:06.862146Z",
     "iopub.status.busy": "2022-09-12T19:10:06.861177Z",
     "iopub.status.idle": "2022-09-12T19:10:06.945011Z",
     "shell.execute_reply": "2022-09-12T19:10:06.943629Z",
     "shell.execute_reply.started": "2022-09-12T19:10:06.862104Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFJob status: Succeeded\n"
     ]
    }
   ],
   "source": [
    "print(f\"TFJob status: {tfjob_client.get_job_conditions(tfjob_name, namespace=namespace, job_kind='TFJob')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f247670e-0bd4-4336-a40c-605ce32fad23",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-09-12T19:10:11.765592Z",
     "iopub.status.busy": "2022-09-12T19:10:11.764384Z",
     "iopub.status.idle": "2022-09-12T19:10:14.249858Z",
     "shell.execute_reply": "2022-09-12T19:10:14.248518Z",
     "shell.execute_reply.started": "2022-09-12T19:10:11.765560Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12T19:10:11Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:08:53Z INFO     --------------------------------------------------------------------------------------\n",
      "2022-09-12T19:10:11Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:08:53Z INFO     Input Parameters: {'lr': '0.17016692449867332', 'num_epoch': '13', 'is_dist': True, 'num_workers': 5}\n",
      "2022-09-12T19:10:11Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:08:53Z INFO     --------------------------------------------------------------------------------------\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: 2022-09-12 19:08:53.988515: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: 2022-09-12 19:08:54.008619: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> train-mnist-worker-0.kubeflow-andrey.svc:2222, 1 -> train-mnist-worker-1.kubeflow-andrey.svc:2222, 2 -> train-mnist-worker-2.kubeflow-andrey.svc:2222, 3 -> train-mnist-worker-3.kubeflow-andrey.svc:2222, 4 -> train-mnist-worker-4.kubeflow-andrey.svc:2222}\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: 2022-09-12 19:08:54.008700: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> train-mnist-worker-0.kubeflow-andrey.svc:2222, 1 -> train-mnist-worker-1.kubeflow-andrey.svc:2222, 2 -> train-mnist-worker-2.kubeflow-andrey.svc:2222, 3 -> train-mnist-worker-3.kubeflow-andrey.svc:2222, 4 -> train-mnist-worker-4.kubeflow-andrey.svc:2222}\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: 2022-09-12 19:08:54.009579: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://train-mnist-worker-0.kubeflow-andrey.svc:2222\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: INFO:tensorflow:Enabled multi-worker collective ops with available devices: ['/job:worker/replica:0/task:0/device:CPU:0', '/job:worker/replica:0/task:4/device:CPU:0', '/job:worker/replica:0/task:2/device:CPU:0', '/job:worker/replica:0/task:3/device:CPU:0', '/job:worker/replica:0/task:1/device:CPU:0']\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:08:54Z INFO     Enabled multi-worker collective ops with available devices: ['/job:worker/replica:0/task:0/device:CPU:0', '/job:worker/replica:0/task:4/device:CPU:0', '/job:worker/replica:0/task:2/device:CPU:0', '/job:worker/replica:0/task:3/device:CPU:0', '/job:worker/replica:0/task:1/device:CPU:0']\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: INFO:tensorflow:Check health not enabled.\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:08:54Z INFO     Check health not enabled.\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['train-mnist-worker-0.kubeflow-andrey.svc:2222', 'train-mnist-worker-1.kubeflow-andrey.svc:2222', 'train-mnist-worker-2.kubeflow-andrey.svc:2222', 'train-mnist-worker-3.kubeflow-andrey.svc:2222', 'train-mnist-worker-4.kubeflow-andrey.svc:2222']}, task_type = 'worker', task_id = 0, num_workers = 5, local_devices = ('/job:worker/task:0/device:CPU:0',), communication = CommunicationImplementation.RING\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:08:54Z INFO     MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['train-mnist-worker-0.kubeflow-andrey.svc:2222', 'train-mnist-worker-1.kubeflow-andrey.svc:2222', 'train-mnist-worker-2.kubeflow-andrey.svc:2222', 'train-mnist-worker-3.kubeflow-andrey.svc:2222', 'train-mnist-worker-4.kubeflow-andrey.svc:2222']}, task_type = 'worker', task_id = 0, num_workers = 5, local_devices = ('/job:worker/task:0/device:CPU:0',), communication = CommunicationImplementation.RING\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:08:56Z INFO     Running Distributed Training\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:08:56Z INFO     --------------------------------------------------------------------------------------\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: 2022-09-12 19:08:56.666389: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: op: \"TensorSliceDataset\"\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: input: \"Placeholder/_0\"\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: input: \"Placeholder/_1\"\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: attr {\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:   key: \"Toutput_types\"\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:   value {\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:     list {\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:       type: DT_FLOAT\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:       type: DT_INT64\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:     }\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:   }\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: }\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: attr {\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:   key: \"_cardinality\"\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:   value {\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:     i: 60000\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:   }\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: }\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: attr {\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:   key: \"is_files\"\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:   value {\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:     b: false\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:   }\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: }\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: attr {\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:   key: \"metadata\"\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:   value {\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:     s: \"\\n\\024TensorSliceDataset:0\"\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:   }\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: }\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]: attr {\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:   key: \"output_shapes\"\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:   value {\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:     list {\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:       shape {\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:         dim {\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:           size: 28\n",
      "2022-09-12T19:10:12Z INFO     [Pod train-mnist-worker-0]:         }\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:         dim {\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:           size: 28\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:         }\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:       }\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:       shape {\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:       }\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:     }\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:   }\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: }\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: experimental_type {\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:   type_id: TFT_PRODUCT\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:   args {\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:     type_id: TFT_DATASET\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:     args {\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:       type_id: TFT_PRODUCT\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:       args {\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:         type_id: TFT_TENSOR\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:         args {\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:           type_id: TFT_FLOAT\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:         }\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:       }\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:       args {\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:         type_id: TFT_TENSOR\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:         args {\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:           type_id: TFT_INT64\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:         }\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:       }\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:     }\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]:   }\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: }\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: 2022-09-12 19:08:56.901683: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:08:57Z INFO     Collective all_reduce tensors: 6 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: INFO:tensorflow:Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:08:57Z INFO     Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: INFO:tensorflow:Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:08:57Z INFO     Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: INFO:tensorflow:Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:08:57Z INFO     Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: INFO:tensorflow:Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:08:57Z INFO     Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: INFO:tensorflow:Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:08:57Z INFO     Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:08:58Z INFO     Collective all_reduce tensors: 6 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: INFO:tensorflow:Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:08:58Z INFO     Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: INFO:tensorflow:Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:08:58Z INFO     Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: INFO:tensorflow:Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:08:58Z INFO     Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: INFO:tensorflow:Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:13Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:08:58Z INFO     Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 5, implementation = CommunicationImplementation.RING, num_packs = 1\n",
      "2022-09-12T19:10:14Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:09:04Z INFO     Epoch 1/13. accuracy=0.7755 - loss=0.7565\n",
      "2022-09-12T19:10:14Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:09:09Z INFO     Epoch 2/13. accuracy=0.9104 - loss=0.2964\n",
      "2022-09-12T19:10:14Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:09:13Z INFO     Epoch 3/13. accuracy=0.9371 - loss=0.2100\n",
      "2022-09-12T19:10:14Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:09:18Z INFO     Epoch 4/13. accuracy=0.9475 - loss=0.1756\n",
      "2022-09-12T19:10:14Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:09:23Z INFO     Epoch 5/13. accuracy=0.9505 - loss=0.1612\n",
      "2022-09-12T19:10:14Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:09:27Z INFO     Epoch 6/13. accuracy=0.9608 - loss=0.1309\n",
      "2022-09-12T19:10:14Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:09:32Z INFO     Epoch 7/13. accuracy=0.9613 - loss=0.1298\n",
      "2022-09-12T19:10:14Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:09:37Z INFO     Epoch 8/13. accuracy=0.9645 - loss=0.1165\n",
      "2022-09-12T19:10:14Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:09:41Z INFO     Epoch 9/13. accuracy=0.9717 - loss=0.0962\n",
      "2022-09-12T19:10:14Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:09:46Z INFO     Epoch 10/13. accuracy=0.9719 - loss=0.0920\n",
      "2022-09-12T19:10:14Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:09:51Z INFO     Epoch 11/13. accuracy=0.9743 - loss=0.0873\n",
      "2022-09-12T19:10:14Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:09:55Z INFO     Epoch 12/13. accuracy=0.9751 - loss=0.0831\n",
      "2022-09-12T19:10:14Z INFO     [Pod train-mnist-worker-0]: 2022-09-12T19:10:00Z INFO     Epoch 13/13. accuracy=0.9765 - loss=0.0803\n"
     ]
    }
   ],
   "source": [
    "tfjob_client.get_job_logs(name=tfjob_name, namespace=namespace, is_master=True, follow=True, job_kind=\"TFJob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227c0a9a-fdf5-4047-b0e2-ec15d3c120ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:50:29.596391Z",
     "iopub.status.busy": "2022-08-09T23:50:29.596145Z",
     "iopub.status.idle": "2022-08-09T23:50:29.599222Z",
     "shell.execute_reply": "2022-08-09T23:50:29.598674Z",
     "shell.execute_reply.started": "2022-08-09T23:50:29.596363Z"
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Delete Katib Experiment and TFJob\n",
    "\n",
    "When jobs are finished, you can delete the resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd24acd8-4305-463e-a6e6-eed16d8a7c51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-12T19:10:19.053646Z",
     "iopub.status.busy": "2022-09-12T19:10:19.052424Z",
     "iopub.status.idle": "2022-09-12T19:10:19.144593Z",
     "shell.execute_reply": "2022-09-12T19:10:19.143396Z",
     "shell.execute_reply.started": "2022-09-12T19:10:19.053607Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment tune-mnist has been deleted\n"
     ]
    }
   ],
   "source": [
    "katib_client.delete_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "025fa4af-256d-4027-99ba-ba44c1409541",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-09-12T19:10:19.532471Z",
     "iopub.status.busy": "2022-09-12T19:10:19.531949Z",
     "iopub.status.idle": "2022-09-12T19:10:19.550331Z",
     "shell.execute_reply": "2022-09-12T19:10:19.549103Z",
     "shell.execute_reply.started": "2022-09-12T19:10:19.532441Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12T19:10:19Z INFO     TFJob train-mnist has been deleted\n"
     ]
    }
   ],
   "source": [
    "tfjob_client.delete_job(tfjob_name, namespace=namespace, job_kind=\"TFJob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e238a638-cf77-423f-a346-f763fc8b1582",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
